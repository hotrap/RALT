#ifndef VISCNTS_SST_H__
#define VISCNTS_SST_H__

#include <vector>
#include "fileenv.hpp"
#include "fileblock.hpp"
#include "alloc.hpp"
#include "writebatch.hpp"
#include "bloomfilter.hpp"

namespace viscnts_lsm {


const static size_t kMagicNumber = 0x25a65facc3a23559;  // echo viscnts | sha1sum
const static size_t kPageSize = 16 << 10;
constexpr size_t kSSTable = 1ull << 24;

template <typename KeyCompT, typename ValueT>
class SSTIterator {
 public:
  using DataKey = BlockKey<SKey, ValueT>;
  SSTIterator() {}
  SSTIterator(typename FileBlock<DataKey, KeyCompT>::EnumIterator&& file_block_iter) 
    : file_block_iter_(std::move(file_block_iter)) {}
  SSTIterator(SSTIterator&& it) noexcept {
    file_block_iter_ = std::move(it.file_block_iter_);
  }
  SSTIterator& operator=(SSTIterator&& it) noexcept {
    file_block_iter_ = std::move(it.file_block_iter_);
    return *this;
  }
  SSTIterator& operator=(const SSTIterator& it) {
    file_block_iter_ = it.file_block_iter_;
    return *this;
  }
  bool valid() { return file_block_iter_.valid(); }
  // ensure it's valid.
  void next() { file_block_iter_.next(); }
  // remember, SKey is a reference to file block
  void read(DataKey& kv) { file_block_iter_.read(kv); }

  int rank() { return file_block_iter_.rank(); }

  // void jump(int new_id) { file_block_iter_.jump(new_id); }

 private:
  typename FileBlock<DataKey, KeyCompT>::EnumIterator file_block_iter_;
};


// one SST
template <typename KeyCompT, typename ValueT, typename IndexDataT>
class ImmutableFile {
  // The structure of the file:
  // [A data block]
  // [A index block]
  // [offset of index block, size, counts_]
  // [offset of data block, size, counts_]
  // [kMagicNumber] (8B)
  // Now we don't consider crash consistency
  // leveldb drops the shared prefix of a key which is not restart point, here we don't consider the compression now

  // we assume the length of key is < 4096.
  // from metadata file
  uint32_t file_id_;
  uint32_t size_;  // the size of the file
  // range is stored in memory
  std::pair<IndSKey, IndSKey> range_;
  // filename is not stored in metadata file, it's generated by file_id and the filename of the metadata file
  // std::string filename_;
  std::unique_ptr<RandomAccessFile> file_ptr_;
  FileBlock<BlockKey<SKey, IndexDataT>, KeyCompT> index_block_;
  FileBlock<BlockKey<SKey, ValueT>, KeyCompT> data_block_;
  // LRUCache pointer reference to the one in VisCnts (is deleted)
  KeyCompT comp_;

  
  class FileOpen {
    public:
      FileOpen(RandomAccessFile* file) : file_(file) { fd_ = file_->get_fd(); }
      ~FileOpen() { file_->release_fd(fd_); }
      int get_fd() const { return fd_; } 
      
    private:
      RandomAccessFile* file_;
      int fd_;
  };

  FileOpen open_ra_file_;

  using DataKey = BlockKey<SKey, ValueT>;
  using IndexKey = BlockKey<SKey, IndexDataT>;

 public:

  // Used in seek. We get a temporary fd before seeking, and release it after seeking.
  // We don't use it now.
  // class TempFileOpen {
  //   public:
  //     TempFileOpen(const ImmutableFile<KeyCompT, ValueT, IndexDataT>& file) : file_(file) { fd_ = file_.file_ptr_->get_fd(); }
  //     ~TempFileOpen() { file_.file_ptr_->release_fd(fd_); }
  //     int get_fd() const { return fd_; } 
      
  //   private:
  //     const ImmutableFile<KeyCompT, ValueT, IndexDataT>& file_;
  //     int fd_;
  // };


  ImmutableFile(uint32_t file_id, uint32_t size, std::unique_ptr<RandomAccessFile>&& file_ptr, 
                const std::pair<IndSKey, IndSKey>& range, FileChunkCache* file_index_cache, FileChunkCache* file_key_cache, 
                KeyCompT comp)
      : file_id_(file_id), size_(size), range_(range), file_ptr_(std::move(file_ptr)), comp_(comp), open_ra_file_(file_ptr_.get()) {
    // read index block
    int ra_fd = open_ra_file_.get_fd();
    FileBlockHandle index_bh, data_bh;
    size_t mgn;
    Chunk c;
    c.allocate();
    DB_ASSERT(size_ % kChunkSize == 0 && size_ > 0);
    auto ret = file_ptr_->read(ra_fd, size_ - kChunkSize, kChunkSize, c.data());
    mgn = *(size_t*)(c.data() + sizeof(FileBlockHandle) * 2);
    index_bh = *(FileBlockHandle*)(c.data() + sizeof(FileBlockHandle));
    data_bh = *(FileBlockHandle*)(c.data());
    DB_ASSERT(ret >= 0);
    DB_ASSERT(mgn == kMagicNumber);
    DB_ASSERT(index_bh.size % kChunkSize == 0 && index_bh.offset % kChunkSize == 0);
    DB_ASSERT(data_bh.size % kChunkSize == 0 && data_bh.offset % kChunkSize == 0);
    // DB_INFO("{}, {}", index_bh.offset, data_bh.offset);
    index_block_ = FileBlock<IndexKey, KeyCompT>(file_id, index_bh, file_ptr_.get(), file_index_cache, comp_);
    data_block_ = FileBlock<DataKey, KeyCompT>(file_id, data_bh, file_ptr_.get(), file_key_cache, comp_);
  }

  // seek the first key that >= key, but only seek index block.
  typename FileBlock<DataKey, KeyCompT>::EnumIterator estimate_seek(SKey key) {
    if (comp_(range_.second.ref(), key) < 0) return {};
    auto id = index_block_.get_maximum_proper_value(key, open_ra_file_.get_fd(), [&](auto my, auto it) {
      return comp_(it, my) <= 0;
    });
    if (!id) return {};
    return data_block_.seek_chunk_begin(std::get<2>(id.value()).get_offset() / kChunkSize, 0, std::get<2>(id.value()).get_id());
  }

  // seek the first key that >= key
  typename FileBlock<DataKey, KeyCompT>::EnumIterator seek(SKey key) const {
    if (comp_(range_.second.ref(), key) < 0) return {};
    // DB_INFO("<<< {}", size_t(this));
    auto id = index_block_.get_maximum_proper_value(key, open_ra_file_.get_fd(), [&](auto my, auto it) {
      return comp_(it, my) <= 0;
    });
    if (!id) {
      return seek_to_first();
    }
    // DB_INFO(">>> {}, {}, {}, {}", std::get<2>(id.value()).get_id(), std::get<2>(id.value()).get_offset(), std::get<0>(id.value()), std::get<1>(id.value()));
    return data_block_.lower_in_chunk(key, std::get<2>(id.value()).get_offset(), std::get<2>(id.value()).get_id(), open_ra_file_.get_fd());
  }

  
  typename FileBlock<DataKey, KeyCompT>::EnumIterator seek_to_first() const {
    return data_block_.seek_chunk_begin(0, 0, 0);
  }

  size_t estimate_range_hot_size(const std::pair<SKey, SKey>& range) const {
    size_t retl = 0, retr = 0;
    auto& [L, R] = range;
    if (comp_(L, R) > 0) {
      return 0;
    }
    return index_block_.get_prefix_size_sum(R, open_ra_file_.get_fd(), false) - index_block_.get_prefix_size_sum(L, open_ra_file_.get_fd(), true);
  }

  bool in_range(SKey key) {
    auto& [l, r] = range_;
    return comp_(l.ref(), key) <= 0 && comp_(key, r.ref()) <= 0;
  }
  std::pair<SKey, SKey> range() const { return {range_.first.ref(), range_.second.ref()}; }

  size_t size() const { return size_; }

  size_t data_size() const { return data_block_.size(); }

  size_t counts() const { return data_block_.counts(); }

  bool range_overlap(const std::pair<SKey, SKey>& range) const {
    auto& [l, r] = range_;
    return comp_(l.ref(), range.second) <= 0 && comp_(range.first, r.ref()) <= 0;
  }

  FileBlock<DataKey, KeyCompT> data_block() const { return data_block_; }

  void remove() {
    auto ret = file_ptr_->remove();
    assert(ret >= 0);
  }
};

class BlockBuilder {
  using OffsetTy = uint32_t;
  std::vector<OffsetTy> offsets_;
  OffsetTy block_offset_{0};
  OffsetTy block_size_{0};
  OffsetTy current_offset_{0};
  bool is_finished_{false};


 public:
  struct Header {
    OffsetTy cnt_;
  };


  void NewBlock(OffsetTy block_offset) {
    block_offset_ = block_offset;
    current_offset_ = block_offset;
    block_size_ = sizeof(Header);
    is_finished_ = false;
    offsets_.clear();
  }

  template<typename DataKey>
  bool CanAppend(const DataKey& kv) const {
    if (kv.serialize_size() + sizeof(OffsetTy) + block_size_ <= kChunkSize) {
      return true;
    }
    return false;
  }

  template<typename DataKey>
  void Append(WriteBatch& file, const DataKey& kv) {
    file.append_key(kv);
    offsets_.push_back(current_offset_);
    current_offset_ += kv.serialize_size();
    block_size_ += kv.serialize_size() + sizeof(OffsetTy);
  }

  size_t Finish(WriteBatch& file) {
    if ((sizeof(OffsetTy) * offsets_.size() + current_offset_ + sizeof(Header)) % kChunkSize > 0) {
      file.fill(0, kChunkSize - (sizeof(OffsetTy) * offsets_.size() + current_offset_ + sizeof(Header)) % kChunkSize);
    }
    for (auto x : offsets_) {
      file.append_other(x - block_offset_);
    }
    file.append_other(Header{.cnt_ = (uint32_t)offsets_.size()});
    current_offset_ += kChunkSize - current_offset_ % kChunkSize;
    is_finished_ = true;
    return current_offset_;
  }
  bool IsFinished() const {
    return is_finished_;
  }
};

template<typename ValueT, typename IndexDataT>
class SSTBuilder {
  std::unique_ptr<WriteBatch> file_;

  void _align() {
    if (now_offset_ % kChunkSize != 0) {
      file_->fill(0, kChunkSize - now_offset_ % kChunkSize);
      now_offset_ += kChunkSize - now_offset_ % kChunkSize;
    }
  }

  void _append_align(size_t len) {
    if (len && (now_offset_ + len - 1) / kChunkSize != now_offset_ / kChunkSize) {
      _align();
    }
  }

  using DataKey = BlockKey<SKey, ValueT>;
  using IndexKey = BlockKey<SKey, IndexDataT>;

 public:
  SSTBuilder() = default;

  SSTBuilder(std::unique_ptr<WriteBatch>&& file, size_t bloom_bfk) : 
    file_(std::move(file)), now_offset_(0), lst_offset_(0), counts_(0), size_(0), bloom_bfk_(bloom_bfk) {}
  void append(const DataKey& kv, bool is_hot) {
    assert(kv.key().len() > 0);
    // If the block is full, then it is finished.
    if (key_n_ && !current_block_.CanAppend(kv)) {
      now_offset_ = current_block_.Finish(*file_);
    }
    if (!key_n_ || current_block_.IsFinished()) {
      current_block_.NewBlock(now_offset_);
      // If it is the first element, then the second parameter (cumulative sum) should be empty.
      // Otherwise, we use the data of the last element.
        // DB_INFO("index key hash = {}", BloomFilter::BloomHash(kv.key()));
      IndexDataT new_index_block(now_offset_, key_n_, index.size() ? index.back().second : IndexDataT());
      index.emplace_back(kv.key(), new_index_block);
      if (!key_n_) first_key = kv.key();
    }
    if (is_hot) {
      keys_.emplace_back(BloomFilter::BloomHash(kv.key()), kv.value().is_stable());
    }
    stable_cnt_ += kv.value().is_stable();
    index.back().second.add(kv.key(), kv.value());
    current_block_.Append(*file_, kv);
    size_ += kv.serialize_size();
    key_n_ += 1;
  }
  template <typename Value>
  void append(const std::pair<SKey, Value>& kv, bool is_hot) {
    append(DataKey(kv.first, kv.second), is_hot);
  }
  template <typename Value>
  void append(const std::pair<IndSKey, Value>& kv, bool is_hot) {
    append(DataKey(kv.first.ref(), kv.second), is_hot);
  }

  template<typename T>
  void set_lstkey(const T& key) {
    lst_key = key;
  }

  void make_index() {
    // append all the offsets in the data block
    now_offset_ = current_block_.Finish(*file_);
    auto data_bh = FileBlockHandle(0, now_offset_, key_n_);
    lst_offset_ = now_offset_;
    std::vector<uint32_t> v;
    current_block_.NewBlock(now_offset_);
    // append keys in the index block
    for (const auto& a : index) {
      IndexKey index_key(a.first.ref(), a.second);
      if (!current_block_.CanAppend(index_key)) {
        now_offset_ = current_block_.Finish(*file_);
        current_block_.NewBlock(now_offset_);
      }
      current_block_.Append(*file_, index_key);
    }
    now_offset_ = current_block_.Finish(*file_);
    _align();
    auto index_bh = FileBlockHandle(lst_offset_, now_offset_ - lst_offset_, index.size());  
    // append two block handles.
    // write offset of index block
    file_->append_other(data_bh);
    file_->append_other(index_bh);
    now_offset_ += sizeof(FileBlockHandle) * 2;
  }
  void finish() {
    file_->append_other(kMagicNumber);
    now_offset_ += sizeof(size_t);
    _align();
    file_->flush();
  }
  void reset() {
    now_offset_ = 0;
    lst_offset_ = 0;
    counts_ = 0;
    size_ = 0;
    stable_cnt_ = 0;
    key_n_ = 0;
    index.clear();
    offsets.clear();
    keys_.clear();
    check_hot_buffer_.clear();
    check_stably_hot_buffer_.clear();
  }
  void new_file(std::unique_ptr<WriteBatch>&& file, size_t bloom_bfk) {
    file_ = std::move(file);
    bloom_bfk_ = bloom_bfk;
    assert(file_ != nullptr);
  }

  size_t size() { return now_offset_; }
  size_t kv_size() { return size_; }
  size_t get_key_n() const {
    return key_n_;
  }

  std::pair<IndSKey, IndSKey> range() {
    if (index.size())
      return {first_key, lst_key};
    else
      return {};
  }

  size_t get_write_bytes() const {
    return file_ ? file_->get_stat_flushed_size() : 0;
  }

  IndSlice& get_check_hot_buffer() {
    return check_hot_buffer_;
  }

  IndSlice& get_check_stably_hot_buffer() {
    return check_stably_hot_buffer_;
  }

  void make_bloom() {
    BloomFilter bf(bloom_bfk_);
    size_t stable_cnt_in_hot = 0;
    for (auto& [k, is_stably_hot] : keys_) {
      stable_cnt_in_hot += is_stably_hot;
    }
    check_hot_buffer_ = bf.Create(keys_.size() - stable_cnt_in_hot);
    check_stably_hot_buffer_ = bf.Create(stable_cnt_in_hot);
    for (auto& [k, is_stably_hot] : keys_) {
      if (is_stably_hot) {
        bf.Add(k, check_stably_hot_buffer_);
      } else {
        bf.Add(k, check_hot_buffer_);
      }
    }
  }

 private:
  uint32_t now_offset_{0}, lst_offset_{0}, counts_{0}, size_{0};
  std::vector<std::pair<IndSKey, IndexDataT>> index;
  std::vector<std::pair<size_t, int>> keys_;
  std::vector<uint32_t> offsets;
  IndSKey lst_key, first_key;
  IndSlice check_hot_buffer_;
  IndSlice check_stably_hot_buffer_;
  size_t stable_cnt_{0};
  size_t key_n_{0};
  size_t bloom_bfk_{0};
  BlockBuilder current_block_;
};

}

#endif